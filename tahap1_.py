# -*- coding: utf-8 -*-
"""Tahap1..ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xxpd3jCo4nMH20haLksXdRneK1he-Ngb
"""

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Upload file jika dijalankan di Google Colab
uploaded = files.upload()

# Load dataset
file_path = list(uploaded.keys())[0]  # Ambil nama file yang diunggah
df = pd.read_csv(file_path)

# Cek jumlah missing values di setiap kolom
missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0]

if missing_values.empty:
    print("Tidak ada missing values dalam dataset.")
else:
    print("Terdapat missing values:")
    print(missing_values)

# Menggunakan quality dalam clustering
X = df.copy()  # Gunakan semua fitur termasuk 'quality'
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Tentukan jumlah klaster optimal dengan Elbow Method
wcss = []
for i in range(2, 10):
    kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.plot(range(2, 10), wcss, marker='o')
plt.xlabel("Jumlah Klaster")
plt.ylabel("WCSS")
plt.title("Metode Elbow untuk Menentukan Jumlah Klaster")
plt.show()

# Jumlah klaster yang digunakan
n_clusters = 6
print(f"Jumlah klaster yang digunakan: {n_clusters}")

# Klasterisasi menggunakan K-Means (Termasuk Quality)
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)

# Evaluasi hasil klasterisasi
silhouette_score_kmeans = silhouette_score(X_scaled, clusters)
davies_bouldin_kmeans = davies_bouldin_score(X_scaled, clusters)

print(f"Indeks Silhouette (K-Means): {silhouette_score_kmeans:.4f}")
print(f"Davies-Bouldin Index (K-Means): {davies_bouldin_kmeans:.4f}")

# Reduksi dimensi dengan PCA untuk visualisasi
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='coolwarm', alpha=0.6, edgecolors='k')
plt.title("Visualisasi PCA dengan Cluster K-Means (Quality Disertakan)")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.colorbar(label="Cluster")
plt.show()

# Tambahkan label cluster ke dalam dataset
df["Cluster"] = clusters
print("Dataset dengan label cluster:")
print(df.head())

X_train, X_test, y_train, y_test = train_test_split(X_scaled, df["quality"], test_size=0.2, random_state=42)

# Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

# Support Vector Machine (SVM) dengan kernel linear
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)
print("SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm, zero_division=1))

# K-Nearest Neighbors (KNN)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))
# -*- coding: utf-8 -*-
"""K-Means & Hierarchical..ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O0ZvE3OFHG0-OoSFnGnJeAe2HCzOhsXO
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import adjusted_rand_score
from scipy.cluster.hierarchy import dendrogram, linkage

# Load dataset
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('winequality-red.csv')

# Simpan kolom quality untuk analisis nanti, tapi tidak digunakan dalam clustering
df_hidden = df.drop(columns=["quality"], errors='ignore')

# Standarisasi data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_hidden)

# Buat linkage matrix untuk hierarchical clustering
linked = linkage(X_scaled, method='ward')

# Plot dendrogram
plt.figure(figsize=(10, 6))
dendrogram(linked, truncate_mode='level', p=5)
plt.title("Dendrogram untuk Menentukan Jumlah Klaster")
plt.xlabel("Data Points")
plt.ylabel("Euclidean Distance")
plt.show()

# Hierarchical Clustering dengan jumlah klaster optimal
hierarchical = AgglomerativeClustering(n_clusters=6)
hierarchical_labels = hierarchical.fit_predict(X_scaled)

# Cek distribusi cluster
print(pd.Series(hierarchical_labels).value_counts())

from sklearn.metrics import silhouette_score, davies_bouldin_score, homogeneity_score, completeness_score, v_measure_score

# Jalankan K-Means dengan jumlah klaster sama
kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init=10)
kmeans_labels = kmeans.fit_predict(X_scaled)

# Bandingkan hasil kedua metode
score = adjusted_rand_score(hierarchical_labels, kmeans_labels)
print(f"Kesamaan antara Hierarchical & K-Means: {score:.4f}")

# Evaluasi Silhouette Score
silhouette = silhouette_score(X_scaled, kmeans_labels)
print(f"Silhouette Score: {silhouette:.4f}")

# Evaluasi Davies-Bouldin Index
db_index = davies_bouldin_score(X_scaled, kmeans_labels)
print(f"Davies-Bouldin Index: {db_index:.4f}")

# Evaluasi Homogeneity, Completeness, dan V-Measure
homogeneity = homogeneity_score(hierarchical_labels, kmeans_labels)
completeness = completeness_score(hierarchical_labels, kmeans_labels)
v_measure = v_measure_score(hierarchical_labels, kmeans_labels)

print(f"Homogeneity Score: {homogeneity:.4f}")
print(f"Completeness Score: {completeness:.4f}")
print(f"V-Measure Score: {v_measure:.4f}")

from sklearn.decomposition import PCA

# Reduksi dimensi ke 2D dengan PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Plot hasil clustering
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6, edgecolors='k')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200, label="Centroid")
plt.title("Hybrid Clustering: Hierarchical + K-Means")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.legend()
plt.show()

# Tambahkan label klaster ke data asli (tanpa quality)
df_hidden["Cluster"] = kmeans_labels

# Hitung statistik deskriptif per klaster
summary = df_hidden.groupby("Cluster").agg(["mean", "std", "min", "max"])
print(summary)